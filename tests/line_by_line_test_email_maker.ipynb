{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line-by-line test of the emailer pipeline\n",
    "\n",
    "This is a notebook that tests the main script `0_email_maker` line by line with outputs for the purpose of debugging. The main script follows these steps:\n",
    "1. import installed packages and supporting modules\n",
    "2. set up directories and logging\n",
    "3. grab data from aws database\n",
    "4. random assignment\n",
    "5. save at risk permits data and assignment\n",
    "6. generate emails with at risk permits data\n",
    "7. save email files and sync with s3 bucket in whippet\n",
    "\n",
    "This notebook tests each of the code block and validates outputs.\n",
    "\n",
    "## Prerequisites for replication:\n",
    "1. must have Sherlock OAK and GROUP_SCRATCH mounted on your local machine, see [guide](https://asconfluence.stanford.edu/confluence/display/REGLAB/Mount+Sherlock+Folders+to+your+local+machine+-SSHFS).\n",
    "2. must have saved OAK and GROUP_SCRATCH as environment variables in your `.bash_profile` or `.zshrc` file. For example, \n",
    "```\n",
    "# sherlock directories\n",
    "export OAK=\"~/sherlock_oak\"\n",
    "export GROUP_SCRATCH=\"~/sherlock_group_scratch\"\n",
    "```\n",
    "3. must have the `esnc_risk_notif` git repo cloned to our local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first set working directory as where the 0_email_maker will sit\n",
    "import os \n",
    "\n",
    "os.chdir('..')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: import packages\n",
    "\n",
    "In this step, we are checking whether all the required modules have been installed in the environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import installed packages\n",
    "import os\n",
    "import argparse\n",
    "import subprocess\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "# import supporting modules\n",
    "import configs\n",
    "from utilities import sql_grab\n",
    "from utilities import sql_save\n",
    "from utilities import sql_queries\n",
    "from utilities import json_functions\n",
    "from utilities import templating\n",
    "from utilities import random_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parsed arguments \n",
    "mode = 'test'\n",
    "model_id = 'esnc_notif_2021Q4_2021-08-03_122849_569766'\n",
    "quarter = '2021Q4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: set up directories and logging\n",
    "\n",
    "In this step, we are configuring directories and logging file. We should expect to see global variables from `configs` read correctly and the logging file prints out relevant lines. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Block "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(configs.HELPER_TEXT_EMAIL_MAKER)\n",
    "print('===== Start running email maker =====')\n",
    "\n",
    "# ## get parsed variables\n",
    "# args = get_args()\n",
    "# mode = args.mode\n",
    "# model_id = args.model_id\n",
    "# quarter = args.quarter\n",
    "\n",
    "## get global variables \n",
    "engine = configs.GET_ENGINE()\n",
    "bucket = configs.BUCKET\n",
    "seed = configs.SEED\n",
    "states_list = configs.STATES_LIST\n",
    "classification_threshold = configs.CLASSIFICATION_THRESHOLD\n",
    "\n",
    "## generate run id\n",
    "runtime = dt.datetime.now()\n",
    "runtime_str = str(runtime).replace(' ', '_').replace(':', '').replace('.', '_')\n",
    "run_id = quarter + '_' + runtime_str \n",
    "\n",
    "## create folders for the current run \n",
    "oak_project_dir = configs.GET_OAK_PROJECT_DIR()\n",
    "s3_project_dir = configs.S3_PROJECT_DIR\n",
    "oak_run_dir = os.path.join(oak_project_dir, mode, run_id)\n",
    "assert not os.path.exists(oak_run_dir), \"The output directoary already exists. Aborting.\"\n",
    "\n",
    "oak_log_dir = os.path.join(oak_run_dir, 'logs')\n",
    "oak_emails_dir = os.path.join(oak_run_dir, 'emails')\n",
    "list(map(os.makedirs, [oak_run_dir, oak_log_dir, oak_emails_dir]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## configure logging\n",
    "logger, log_capture_string = configs.configure_logging(logger_name = 'email_maker')\n",
    "logger.info(configs.HELPER_TEXT_EMAIL_MAKER)\n",
    "logger.info(\"Configured logger\")\n",
    "logger.info(\"----- Parsed variables: mode = {}, model_id = {}, quarter = {}\".format(mode, model_id, quarter))\n",
    "logger.info(\"----- Project variables: states_list = {}, classification_threshold = {}\".format(states_list, classification_threshold))\n",
    "logger.info(\"----- Sherlock OAK folders: oak_run_dir = {}\".format(oak_run_dir))\n",
    "logger.info(\"----- S3 bucket: s3_project_dir = {}\".format(s3_project_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## print out variables and let the user confirm if they are correct and whether to proceed. \n",
    "print(\"----- Parsed variables: mode = {}, model_id = {}, quarter = {}\".format(mode, model_id, quarter))\n",
    "print(\"----- Project variables: states_list = {}, classification_threshold = {}\".format(states_list, classification_threshold))\n",
    "print(\"----- Sherlock OAK folders: oak_run_dir = {}\".format(oak_run_dir))\n",
    "print(\"----- S3 bucket: s3_project_dir = {}\".format(s3_project_dir))\n",
    "\n",
    "proceed = input('Please verify the above variables. Do you wish to proceed with the run? [y/n]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### velidate variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log_capture_string.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: grab data from aws database\n",
    "\n",
    "In this step, we are grabbing data with SQL queries from `utilities.sql_queries`. We should expect to check at-risk permits data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### code block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"===== 1/6 Get model result table and database update date =====\")\n",
    "\n",
    "data = sql_grab.get_at_risk_permits(model_id = model_id, states_list = states_list, classification_threshold = classification_threshold, engine = engine)\n",
    "## subset to permits with historical violation records\n",
    "missing_violation_count = sum(data.known_violations.isna())\n",
    "logger.info(f\"Excluding {missing_violation_count} permits without any historical violation records from DMRs in the past three years.\")\n",
    "data = data[~data.known_violations.isna()]\n",
    "assert len(data) != 0, \"Expect more than one at-risk permits. Aborting.\"\n",
    "logger.info(f\"Number of at-risk permits = {len(data)}\")\n",
    "\n",
    "database_update_date = sql_grab.get_database_update_date(engine = engine)\n",
    "logger.info(f\"RegLab AWS database update date: {database_update_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### validate output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: random assignment\n",
    "\n",
    "In this step, we conduct the multi-level randomization scheme. We should expect the levels to be executed sequentially, the `notification_flag`, `sample_violation_flag`, `sample_pollutant_flag` to be complete and eligible, and the logging file prints out the number of permits within each level of randomization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### code block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"====== 2/6 Random Assignment ======\")\n",
    "logger.info(\"--- Level 1: randomly split into 50-50. We will send notifications to half of the permits.\")\n",
    "data = random_assignment.level_one_randomization(df=data, treatment_fraction=0.5, random_seed=seed)\n",
    "assert 'notification_flag' in data.columns.tolist(), \"Expect a column named notification_flag after level one randomization. Aborting.\"\n",
    "assert sum(data.notification_flag.isna()) == 0, \"Expect every permit to have an assignment. Aborting.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"--- Level 2: for those we send a notification to, see if there are violation records in the past quarter. if there are violation records: split half and half, include a violation sample in half of them\")\n",
    "data = random_assignment.level_two_randomization(df=data, treatment_fraction=1, random_seed=seed)\n",
    "assert 'sample_violation_flag' in data.columns.tolist(), \"Expect sample_violation_flag to be in the column list of data. Aborting.\"\n",
    "assert sum(data.sample_violation_flag.isna()) == 0, \"Expect every permit to have an assignment. Aborting.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"--- Level 3: within the facilities for which we will include a sample violation, we will randomize which pollutant to show in the email\")\n",
    "data = random_assignment.level_three_randomization(df=data, random_seed=seed)\n",
    "assert 'sample_pollutant_flag' in data.columns.tolist(), \"Expect sample_pollutant to be in the column list. Aborting\"\n",
    "assert sum(data.sample_pollutant_flag.isna()) == 0, \"Expect every permit to have an assignment. Aborting.\"\n",
    "assert sum(data[data.sample_violation_flag].selected_violation.isna()) == 0, \"Expect permit with sample_violation_flag on to have a selected violation to show. Aborting.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('We have {} at risk permits in total.'.format(len(data)))\n",
    "logger.info(\"We will send a notification to {} permits.\".format(sum(data.notification_flag)))\n",
    "logger.info(\"We will include a sample violation for {} permits.\".format(sum(data.sample_violation_flag)))\n",
    "logger.info(\"We will randomize disclosure of pollutant for {} permits.\".format(sum(data.sample_pollutant_flag)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### validate output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pay special attention to sample_violation_flag, there should be a control pollutant for sample_violation_flag True\n",
    "data[data.sample_violation_flag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log_capture_string.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: save at risk facility data and assignment\n",
    "\n",
    "In this step, we upload the at-risk permit assignments to RegLab's AWS database. We should expect to retrieve the table in the database. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### code block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"====== 3/6 Save at risk permit data and treatment assignment to database ======\")\n",
    "data['file_timestamp'] = runtime\n",
    "sql_save.save_at_risk_permits_assignment(mode=mode, data=data, engine=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### if mode is prod: try doing it again - this should throw an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 'prod':\n",
    "    sql_save.save_at_risk_permits_assignment(mode=mode, data=data, engine=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### validate output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if mode == 'prod':\n",
    "    schema = 'esnc_risk_notif'\n",
    "    table = 'at_risk_permits'\n",
    "elif mode == 'test':\n",
    "    schema = 'sandbox'\n",
    "    table = 'esnc_notif_at_risk_permits'\n",
    "with engine.begin() as conn:\n",
    "    df = pd.read_sql(f\"\"\"\n",
    "    SELECT *\n",
    "    FROM {schema}.{table}\n",
    "    \"\"\", conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: generate emails with at risk facility data\n",
    "\n",
    "In this step, we generate emails with at risk permit data and templates. We should expect to see the sample emails in HTML format. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### code block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('===== 4/6 Generate emails with at-risk permits data and email templates =====')\n",
    "# subset to permits that we will send the notifications to\n",
    "notif_group = data[data.notification_flag]\n",
    "data_dict = notif_group.to_dict('records')\n",
    "database_update_date_lst = [database_update_date]*len(data_dict)\n",
    "email_dicts = list(map(templating.generate_email_dict, data_dict, database_update_date_lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### validate output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. KY - without sample violation\n",
    "2. KY - with sample violation\n",
    "3. MD - without sample violation\n",
    "4. MD - with sample violation\n",
    "5. TN - without sample violation\n",
    "6. TN - with sample violation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(email_dicts) == len(data_dict), \"expect the number of email dicts to be the same as the number of info dicts.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "# 1. KY - without sample violation - this should throw an error\n",
    "i = np.where((~notif_group.sample_violation_flag) & (notif_group.permit_state == 'KY'))[0][0]\n",
    "email_dict = email_dicts[i]\n",
    "display(HTML(email_dict['body']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. KY - with sample violation\n",
    "i = np.where((notif_group.sample_violation_flag) & (notif_group.permit_state == 'KY'))[0][0]\n",
    "email_dict = email_dicts[i]\n",
    "display(HTML(email_dict['body']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. MD - without sample violation\n",
    "i = np.where((~notif_group.sample_violation_flag) & (notif_group.permit_state == 'MD'))[0][0]\n",
    "email_dict = email_dicts[i]\n",
    "display(HTML(email_dict['body']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. MD - with sample violation\n",
    "i = np.where((notif_group.sample_violation_flag) & (notif_group.permit_state == 'MD'))[0][0]\n",
    "email_dict = email_dicts[i]\n",
    "display(HTML(email_dict['body']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. TN - without sample violation\n",
    "i = np.where((~notif_group.sample_violation_flag) & (notif_group.permit_state == 'TN'))[0][0]\n",
    "email_dict = email_dicts[i]\n",
    "display(HTML(email_dict['body']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. TN - with sample violation\n",
    "i = np.where((notif_group.sample_violation_flag) & (notif_group.permit_state == 'TN'))[0][0]\n",
    "email_dict = email_dicts[i]\n",
    "display(HTML(email_dict['body']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional examples: \n",
    "1. when number of parameters triggering ESNC or warning last quarter is 0\n",
    "2. when the number of quarters in ESNC in the past three years is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. when number of parameters triggering ESNC or warning last quarter is 0\n",
    "i = np.where((notif_group.sample_violation_flag) & (~notif_group.triggered_esnc_past_quarter_flag) & (~notif_group.warning_past_quarter_flag) & (notif_group.permit_state != 'KY'))\n",
    "if len(i[0]) > 0: \n",
    "    i = i[0][0]\n",
    "    email_dict = email_dicts[i]\n",
    "    display(HTML(email_dict['body']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. when the number of quarters in ESNC in the past three years is 0\n",
    "i = np.where(notif_group.num_quarters_in_esnc == None)\n",
    "if len(i[0]) > 0: \n",
    "    i = i[0][0]\n",
    "    email_dict = email_dicts[i]\n",
    "    display(HTML(email_dict['body']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: save email files\n",
    "\n",
    "In this step, we are saving email dictionaries as json files to the Sherlock Oak project folder. We should expect to retrieve the files from the folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"====== 5/6 Saving email info to json files ======\")\n",
    "json_functions.save_emails_to_json(email_dicts, emails_dir=oak_emails_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(oak_emails_dir)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file_list = os.listdir(oak_emails_dir)\n",
    "with open(os.path.join(oak_emails_dir, file_list[0]), 'r') as file:\n",
    "    test_dict = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: save log file and sync files to s3 bucket\n",
    "\n",
    "In this step, we save the log file to the Sherlock folder and sync all files to S3 bucket. We should expect to see all new files synced. One quick way to check is to see if the log file in s3 bucket and sherlock folder is the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### code block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('======= 6/6 Saving log file and sync to s3 bucket =======')\n",
    "logger.info(f'Script FINISHED. Log file saved in {oak_log_dir} and all project files synced with S3 bucket.')\n",
    "with open(os.path.join(oak_log_dir, 'email_maker.log'), 'w') as file:\n",
    "    file.write(log_capture_string.getvalue())\n",
    "\n",
    "subprocess.run(['aws', 's3', 'sync', oak_project_dir, s3_project_dir], check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### validate output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the log file in s3 bucket and sherlock folder. they should be the same\n",
    "s3_log_dir = os.path.join(mode, run_id, 'logs')\n",
    "s3_content = bucket.Object(os.path.join(s3_log_dir,'email_maker.log')).get()['Body'].read().decode('utf-8')\n",
    "with open(os.path.join(oak_log_dir, 'email_maker.log'), 'r') as file:\n",
    "    oak_content = file.read()\n",
    "s3_content == oak_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(oak_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "End of notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
